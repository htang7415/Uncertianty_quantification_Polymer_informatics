{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from data_processing import load_and_process_data\n",
    "from models import DropoutModel, train_mcd, predict_mcd\n",
    "from metrics import calculate_metrics, calculate_observed_confidence\n",
    "from post_processing import create_errorbar_plot, plot_abs_error_vs_std, plot_std_histogram, plot_calibration_curve\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 1\n",
    "DROPOUT_RATE = 0.13\n",
    "N_EPOCHS = 500\n",
    "T = 300\n",
    "LEARNING_RATE = 0.00011\n",
    "num_zero_threshold = 3600\n",
    "n_1, n_2, n_3 = 530, 602, 471\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load and process data\n",
    "file_path = \"../data/other_property/Tm.csv\"\n",
    "X_count, Y = load_and_process_data(file_path, num_zero_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "xtrain, xtemp, ytrain, ytemp = train_test_split(X_count, Y, test_size=0.2, random_state=11)\n",
    "xval, xtest, yval, ytest = train_test_split(xtemp, ytemp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create DataLoaders\n",
    "def create_dataloader(x, y, batch_size):\n",
    "    tensor_x = torch.FloatTensor(x.values).to(device)\n",
    "    tensor_y = torch.FloatTensor(y).unsqueeze(1).to(device)\n",
    "    dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
    "    return torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader = create_dataloader(xtrain, ytrain, BATCH_SIZE)\n",
    "val_loader = create_dataloader(xval, yval, BATCH_SIZE)\n",
    "test_loader = create_dataloader(xtest, ytest, BATCH_SIZE)\n",
    "\n",
    "# Initialize model\n",
    "model = DropoutModel(xtrain.shape[1], n_1, n_2, n_3, DROPOUT_RATE).to(device)\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "train_mcd(model, train_loader, N_EPOCHS, LEARNING_RATE)\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "mean_train, std_train = predict_mcd(model, train_loader, T)\n",
    "mean_test, std_test = predict_mcd(model, test_loader, T)\n",
    "# Ensure predictions and standard deviations are 1D arrays\n",
    "mean_train = mean_train.flatten()\n",
    "std_train = std_train.flatten()\n",
    "mean_test = mean_test.flatten()\n",
    "std_test = std_test.flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "confidence_levels = np.arange(0, 1.05, 0.05)\n",
    "train_metrics = calculate_metrics(ytrain, mean_train, std_train, confidence_levels)\n",
    "test_metrics = calculate_metrics(ytest, mean_test, std_test, confidence_levels)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Dataset': ['Training', 'Test'],\n",
    "    'MAE': [train_metrics['MAE'], test_metrics['MAE']],\n",
    "    'RMSE': [train_metrics['RMSE'], test_metrics['RMSE']],\n",
    "    'R2': [train_metrics['R2'], test_metrics['R2']],\n",
    "    'Spearman': [train_metrics['Spearman'], test_metrics['Spearman']],\n",
    "    'Calibration Area': [train_metrics['Calibration Area'], test_metrics['Calibration Area']]\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "create_errorbar_plot(ytrain, mean_train, std_train, 'blue', 'Training')\n",
    "create_errorbar_plot(ytest, mean_test, std_test, 'green', 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot additional figures\n",
    "abs_error_train = np.abs(ytrain - mean_train)\n",
    "abs_error_test = np.abs(ytest - mean_test)\n",
    "\n",
    "plot_abs_error_vs_std(abs_error_train, std_train, 'Training', 'blue')\n",
    "plot_abs_error_vs_std(abs_error_test, std_test, 'Test', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_std_histogram(std_train, 'Training', 'blue')\n",
    "plot_std_histogram(std_test, 'Test', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate observed confidence\n",
    "observed_confidence_train = calculate_observed_confidence(ytrain, mean_train, std_train, confidence_levels)\n",
    "observed_confidence_test = calculate_observed_confidence(ytest, mean_test, std_test, confidence_levels)\n",
    "\n",
    "# Plot calibration curves\n",
    "plot_calibration_curve(confidence_levels, observed_confidence_train, 'Training')\n",
    "plot_calibration_curve(confidence_levels, observed_confidence_test, 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
