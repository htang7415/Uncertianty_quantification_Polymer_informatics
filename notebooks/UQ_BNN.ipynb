{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Import custom modules\n",
    "from data_processing import load_and_process_data\n",
    "from models import BayesianNeuralNetwork, train_bnn, predict_bnn\n",
    "from metrics import calculate_metrics, calculate_observed_confidence\n",
    "from post_processing import create_errorbar_plot, plot_abs_error_vs_std, plot_std_histogram, plot_calibration_curve\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "HYPERPARAMETERS = {\n",
    "    'batch_size': 45,\n",
    "    'hidden_layers': [656, 956, 87],\n",
    "    'epochs': 650,\n",
    "    'learning_rate': 0.00014,\n",
    "    'weight_init_std': 0.11525,\n",
    "    'log_std_init_mean': -3.0908,\n",
    "    'log_std_init_std': 0.32564,\n",
    "    'log_std_clamp': (-5.83775, 4.93684),\n",
    "    'grad_clip_norm': 1.0,\n",
    "    'n_samples_uncertainty': 500,\n",
    "    'num_zero_threshold': 3600\n",
    "}\n",
    "\n",
    "# Load and process data\n",
    "file_path = \"../data/other_property/Tm.csv\"  # Update with your file path\n",
    "X_count, Y = load_and_process_data(file_path, HYPERPARAMETERS['num_zero_threshold'])\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "xtrain, xtemp, ytrain, ytemp = train_test_split(X_count, Y, test_size=0.2, random_state=11)\n",
    "xval, xtest, yval, ytest = train_test_split(xtemp, ytemp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to device\n",
    "xtrain_tensor = torch.tensor(xtrain.values).float().to(device)\n",
    "ytrain_tensor = torch.tensor(ytrain).float().to(device)\n",
    "xval_tensor = torch.tensor(xval.values).float().to(device)\n",
    "yval_tensor = torch.tensor(yval).float().to(device)\n",
    "xtest_tensor = torch.tensor(xtest.values).float().to(device)\n",
    "ytest_tensor = torch.tensor(ytest).float().to(device)\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_data = TensorDataset(xtrain_tensor, ytrain_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=HYPERPARAMETERS['batch_size'], shuffle=True)\n",
    "\n",
    "# Initialize and train the BNN model\n",
    "model = BayesianNeuralNetwork(\n",
    "    n_features=xtrain.shape[1],\n",
    "    hidden_layers=HYPERPARAMETERS['hidden_layers'],\n",
    "    weight_init_std=HYPERPARAMETERS['weight_init_std'],\n",
    "    log_std_init_mean=HYPERPARAMETERS['log_std_init_mean'],\n",
    "    log_std_init_std=HYPERPARAMETERS['log_std_init_std'],\n",
    "    log_std_clamp=HYPERPARAMETERS['log_std_clamp']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "\n",
    "model = model.to(device)\n",
    "train_bnn(model, train_loader, HYPERPARAMETERS['epochs'], HYPERPARAMETERS['learning_rate'], HYPERPARAMETERS['grad_clip_norm'])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training took {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions with uncertainty on training and test data\n",
    "mean_train, std_train = predict_bnn(model, xtrain_tensor.to(device), HYPERPARAMETERS['n_samples_uncertainty'])\n",
    "mean_test, std_test = predict_bnn(model, xtest_tensor.to(device), HYPERPARAMETERS['n_samples_uncertainty'])\n",
    "\n",
    "# Convert predictions to numpy for metric calculation\n",
    "mean_train = mean_train.cpu().numpy()\n",
    "std_train = std_train.cpu().numpy()\n",
    "mean_test = mean_test.cpu().numpy()\n",
    "std_test = std_test.cpu().numpy()\n",
    "\n",
    "# Calibration curve\n",
    "confidence_levels = np.arange(0, 1.05, 0.05)\n",
    "\n",
    "# Calculate metrics\n",
    "train_metrics = calculate_metrics(ytrain, mean_train, std_train, confidence_levels)\n",
    "test_metrics = calculate_metrics(ytest, mean_test, std_test, confidence_levels)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Dataset': ['Training', 'Test'],\n",
    "    'MAE': [train_metrics['MAE'], test_metrics['MAE']],\n",
    "    'RMSE': [train_metrics['RMSE'], test_metrics['RMSE']],\n",
    "    'R2': [train_metrics['R2'], test_metrics['R2']],\n",
    "    'Spearman': [train_metrics['Spearman'], test_metrics['Spearman']],\n",
    "    'Calibration Area': [train_metrics['Calibration Area'], test_metrics['Calibration Area']]\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "create_errorbar_plot(ytrain, mean_train, std_train, 'blue', 'Training')\n",
    "create_errorbar_plot(ytest, mean_test, std_test, 'green', 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot additional figures\n",
    "abs_error_train = np.abs(ytrain - mean_train)\n",
    "abs_error_test = np.abs(ytest - mean_test)\n",
    "\n",
    "plot_abs_error_vs_std(abs_error_train, std_train, 'Training', 'blue')\n",
    "plot_abs_error_vs_std(abs_error_test, std_test, 'Test', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_std_histogram(std_train, 'Training', 'blue')\n",
    "plot_std_histogram(std_test, 'Test', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate observed confidence\n",
    "observed_confidence_train = calculate_observed_confidence(ytrain, mean_train, std_train, confidence_levels)\n",
    "observed_confidence_test = calculate_observed_confidence(ytest, mean_test, std_test, confidence_levels)\n",
    "\n",
    "# Plot calibration curves\n",
    "plot_calibration_curve(confidence_levels, observed_confidence_train, 'Training')\n",
    "plot_calibration_curve(confidence_levels, observed_confidence_test, 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
